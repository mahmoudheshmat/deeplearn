{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Validation\n",
    "<b>Inference</b> is utilizing a trained network to perform predictions.\n",
    "To test for overfitting while training, measure the performance on data in the validation set (separate from the training set).\n",
    "One way to avoid overfitting: dropout\n",
    "\n",
    "Typically 10-20% of original dataset is held out for testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# download and load the training data\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# download and load test data\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: why is test and train data the same? don't we have to takea  portion of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # flatten input tensor\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass with one batch from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "# get class probabilities\n",
    "ps = torch.exp(model(images))\n",
    "# make sure the shape is appropriate: 10 class probabilities for 64 examples\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "top_p, top_class = ps.topk(1, dim=1) \n",
    "# topk will return the highest k value, or the most likely class\n",
    "\n",
    "# look at the most likely class for the first 10 examples\n",
    "print(top_class[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine if predicted classes matches the labels\n",
    "Can just compare the top class and labels, but they are different tensors as top_class is (64, 1) and labels is (64). They need to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "equals = top_class == labels.view(*top_class.shape)\n",
    "print(equals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will calculate the percentage of correct predictions by dividing the sum of all values by the number of values (this works because correct predictions are 1, incorrect are 0). Use .mean()\n",
    "\n",
    "Problem: 'equals' has a type torch.ByteTensor, which torch.mean cannot act on. Need to convert equals to a float tensor below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9.375%\n"
     ]
    }
   ],
   "source": [
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30..  Training Loss: 0.514..  Test Loss: 0.450..  Test Accuracy: 0.838\n",
      "Epoch: 2/30..  Training Loss: 0.387..  Test Loss: 0.408..  Test Accuracy: 0.851\n",
      "Epoch: 3/30..  Training Loss: 0.352..  Test Loss: 0.418..  Test Accuracy: 0.849\n",
      "Epoch: 4/30..  Training Loss: 0.333..  Test Loss: 0.414..  Test Accuracy: 0.849\n",
      "Epoch: 5/30..  Training Loss: 0.316..  Test Loss: 0.377..  Test Accuracy: 0.863\n",
      "Epoch: 6/30..  Training Loss: 0.302..  Test Loss: 0.402..  Test Accuracy: 0.869\n",
      "Epoch: 7/30..  Training Loss: 0.290..  Test Loss: 0.379..  Test Accuracy: 0.870\n",
      "Epoch: 8/30..  Training Loss: 0.282..  Test Loss: 0.426..  Test Accuracy: 0.860\n",
      "Epoch: 9/30..  Training Loss: 0.275..  Test Loss: 0.372..  Test Accuracy: 0.873\n",
      "Epoch: 10/30..  Training Loss: 0.267..  Test Loss: 0.389..  Test Accuracy: 0.868\n",
      "Epoch: 11/30..  Training Loss: 0.265..  Test Loss: 0.373..  Test Accuracy: 0.871\n",
      "Epoch: 12/30..  Training Loss: 0.252..  Test Loss: 0.361..  Test Accuracy: 0.880\n",
      "Epoch: 13/30..  Training Loss: 0.247..  Test Loss: 0.370..  Test Accuracy: 0.877\n",
      "Epoch: 14/30..  Training Loss: 0.242..  Test Loss: 0.382..  Test Accuracy: 0.876\n",
      "Epoch: 15/30..  Training Loss: 0.236..  Test Loss: 0.379..  Test Accuracy: 0.874\n",
      "Epoch: 16/30..  Training Loss: 0.234..  Test Loss: 0.382..  Test Accuracy: 0.870\n",
      "Epoch: 17/30..  Training Loss: 0.229..  Test Loss: 0.379..  Test Accuracy: 0.875\n",
      "Epoch: 18/30..  Training Loss: 0.222..  Test Loss: 0.366..  Test Accuracy: 0.881\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "#model.cuda()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        #images.cuda()\n",
    "        #labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # turn off gradients for validation to save memory and computation\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "        \n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the figure above, the model is getting progressively more accurate at classifying the training set, but not the validation set. This is a case of overfitting and being unable to generalize new data. In the next assignment, I will use dropouts to prevent overfitting the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
