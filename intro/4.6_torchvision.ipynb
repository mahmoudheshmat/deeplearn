{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ])\n",
    "\n",
    "# download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "# batch size above means each load will return 64 images\n",
    "# the images are a tensor of (64, 1, 28, 28)\n",
    "#  so basically, 64 images, one color channel(gray scale), a 28 x 28 pixel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 233,
       "width": 233
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: flatten the batch of images and build a multilayer with 784 input units, 256 hidden units, and 10 output units using random tensors for weights and biases. Using the sigmoid activation for the hidden layer, leave the output layer without an activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show example of image\n",
    "plt.imshow(images[5].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data stored in variable images\n",
    "\n",
    "# features is the flattened tensors as calculated below\n",
    "# needed to flatten image, so resize matrix from 28 x 28 to 784\n",
    "# images.shape[0] = 64\n",
    "features = images.view(images.shape[0], 784)\n",
    "\n",
    "# size of each layer in neural network\n",
    "n_input = 784\n",
    "n_hidden = 256\n",
    "n_output = 10\n",
    "\n",
    "# weights for input to hidden layer\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "\n",
    "# weights for hidden layer to output\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "# bias terms for hidden and output\n",
    "B1 = torch.randn(n_hidden)\n",
    "B2 = torch.randn(n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1 / (1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256])\n"
     ]
    }
   ],
   "source": [
    "# calculate output for hidden layer\n",
    "h = activation(torch.mm(features, W1) + B1)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# calculate output layer\n",
    "out = (torch.mm(h, W2) + B2) # will use softmax instead of activation(sigmoid)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to make a probability distribution that shows the likeliness that an image fits into a particular class (here, the class is the number displayed). We can do this using the softmax function because it's able to normalize the values of the input between 0 and 1 to get a probability distribution that sums to 1.\n",
    "\n",
    "Exercise: Implement a softmax function that performs the softmax calculation and returns the probability distribution for each example in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.sum(torch.exp(x), dim=1).view(64, 1)\n",
    "    # dim=1 takes the sum of columns, dim=0 of rows\n",
    "    # in place of .view(64, 1) may do .view(-1, 1) and torch will determine appropriate digits as 64\n",
    "    \n",
    "probabilities = softmax(out)\n",
    "\n",
    "print(probabilities.shape)\n",
    "\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch has a module that makes building networks much simpler, nn. This is how to do the above problem with this module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256) # (input, output)\n",
    "        # output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # define sigmoid activiation and softmax output\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # pass input tensor through each operation\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a more concise way to define a network using the functional module\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
